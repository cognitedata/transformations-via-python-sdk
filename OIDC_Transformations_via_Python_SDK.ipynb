{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rvTGHFbHUCqa"
   },
   "source": [
    "## Read the Cognite Learn content before running code examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3sS9baFNCsJ4"
   },
   "source": [
    "## 1. Environment set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qb8H5WYaDAgF"
   },
   "source": [
    "### Install the Cognite SDK package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QyOeQPCeDGMV",
    "outputId": "18bd09b0-1425-46ad-dec3-a7dde1816920"
   },
   "outputs": [],
   "source": [
    "%pip install \"cognite-sdk[pandas]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u8i-1mQDDKhc"
   },
   "source": [
    "#### Install the MSAL library\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-BjwC7qlDQP1",
    "outputId": "6301d814-de5c-426f-dcdc-ffc73b9bf65f"
   },
   "outputs": [],
   "source": [
    "%pip install msal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BFI6c51zEn_y"
   },
   "source": [
    "### Connect to Cognite Data Fusion\n",
    "Import all the needed libraries and instantiate the Cognite Client.\n",
    "\n",
    "This client object is how all queries will be sent to the Cognite API to retrieve data.\n",
    "\n",
    "For successfully retreiving the  Cognite Client instance, you need to authenicate msal on your browser. Also, make sure to enter the client secret you generated from the course lesson. Run the cell bellow, copy the code from output and enter it on the [site](https://microsoft.com/devicelogin) and authorize the Learn-participants application. If everything completes successfully you will get the output with the token description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TZr9WTWXfvcA",
    "outputId": "20aadd9f-f33b-41cb-cbf4-bfad2c35c758"
   },
   "outputs": [],
   "source": [
    "from cognite.client import CogniteClient, ClientConfig\n",
    "from cognite.client.credentials import Token\n",
    "from cognite.client.data_classes import OidcCredentials\n",
    "\n",
    "from msal import PublicClientApplication\n",
    "\n",
    "CLIENT_SECRET = \"...\" # Enter secret here\n",
    "\n",
    "# Contact Project Administrator to get these\n",
    "TENANT_ID = \"48d5043c-cf70-4c49-881c-c638f5796997\"\n",
    "CLIENT_ID = \"c9874b3f-a32b-4f04-8193-52eacd5fc37d\"\n",
    "\n",
    "CDF_CLUSTER = \"api\" # api, westeurope-1 etc\n",
    "COGNITE_PROJECT = \"de-transformations\"\n",
    "SCOPES = [f'https://{CDF_CLUSTER}.cognitedata.com/.default']\n",
    "AUTHORITY_HOST_URI = 'https://login.microsoftonline.com'\n",
    "AUTHORITY_URI = AUTHORITY_HOST_URI + '/' + TENANT_ID\n",
    "PORT = 53000\n",
    "app = PublicClientApplication(client_id=CLIENT_ID, authority=AUTHORITY_URI)\n",
    "\n",
    "def authenticate_device_code(app):\n",
    "  # Firstly, check the cache to see if this end user has signed in before\n",
    "  accounts = app.get_accounts()\n",
    "  if accounts:\n",
    "    creds = app.acquire_token_silent(SCOPES, account=accounts[0])\n",
    "  else:\n",
    "    device_flow = app.initiate_device_flow(scopes=SCOPES)\n",
    "    print(device_flow['message']) # print device code to screen\n",
    "    creds = app.acquire_token_by_device_flow(flow=device_flow)\n",
    "  return creds\n",
    "\n",
    "def get_token():\n",
    "  return Token(authenticate_device_code(app)['access_token'])\n",
    "\n",
    "cnf = ClientConfig(\n",
    "  project=COGNITE_PROJECT,\n",
    "  base_url=f'https://{CDF_CLUSTER}.cognitedata.com',\n",
    "  client_name='cognite-python-dev',\n",
    "  credentials=get_token()\n",
    ") \n",
    "client = CogniteClient(cnf)\n",
    "\n",
    "print(client.iam.token.inspect().projects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eRg4NKhduiIu"
   },
   "source": [
    "Set the prefix for recources names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "szsz3qsLueou"
   },
   "outputs": [],
   "source": [
    "PREFIX = \"...\" # enter your name and birth year (or something random)\n",
    "DATASET_NAME = f\"{PREFIX}-ds\"\n",
    "DATABASE_NAME = f\"{PREFIX}-db\"\n",
    "ASSET_NAME = f\"{PREFIX}-root\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BfNP32UfsOMU"
   },
   "source": [
    "### Create credentials for use in Transformations\n",
    "\n",
    "To run a transformation, we should set up OIDC credentials for the source and destination projects. It could be different CDF projects, but we only have one in our case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "urALodMIXPqU"
   },
   "outputs": [],
   "source": [
    "from cognite.client.data_classes import OidcCredentials\n",
    "\n",
    "creds = OidcCredentials(\n",
    "        client_id = CLIENT_ID,\n",
    "        client_secret = CLIENT_SECRET,\n",
    "        scopes = \" \".join(SCOPES),\n",
    "        token_uri = f\"{AUTHORITY_URI}/oauth2/v2.0/token\",\n",
    "        cdf_project_name = COGNITE_PROJECT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijVZrLpetARm"
   },
   "source": [
    "## 2. Prepare RAW resources\n",
    "\n",
    "### Data description\n",
    "\n",
    "We have three tables with the weather data from [The Norwegian Meteorological Institute](https://www.met.no/). You can get the API key on the site and play more with different kinds of meteorologic data from the site. \n",
    "\n",
    "sources.csv - the list of [sources](https://frost.met.no/api.html#/sources) (Sensor Systems) with geospatial metadata,\n",
    "\n",
    "elements.csv - the metadata about the weather and climate [elements](https://frost.met.no/api.html#!/elements/getElements) that are defined for use in the API,\n",
    "\n",
    "observations.csv - the list of [observations](https://frost.met.no/api.html#!/observations/observations) for the particular sources and limited date range.\n",
    "\n",
    "All the data from [FrostAPI](https://frost.met.no/index.html) were saved in CSV tables and provided in the the repository, in data folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxnXgS2w0q64"
   },
   "source": [
    "### Prepare database\n",
    "\n",
    "Create database for RAW tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "KzT_I94GnMPJ",
    "outputId": "16bd3b1c-c796-4469-e29d-fb04593cd0d7"
   },
   "outputs": [],
   "source": [
    "client.raw.databases.create(DATABASE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C2MhUF8k0uIE"
   },
   "source": [
    "List databases and check out our database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aKyvbPq-uPNC",
    "outputId": "7e8e47b9-c550-45b4-9a48-4d0450ab4f03"
   },
   "outputs": [],
   "source": [
    "databases = client.raw.databases.list(limit=-1)\n",
    "for db in databases:\n",
    "  if db.name == DATABASE_NAME:\n",
    "    print(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZQr0MveN06SP"
   },
   "source": [
    "### Prepare tables\n",
    "\n",
    "Create tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "4AqSCv4Lnm_9",
    "outputId": "ecb531f1-0115-427f-a4a0-7809d7318a44"
   },
   "outputs": [],
   "source": [
    "client.raw.tables.create(DATABASE_NAME, \"sources\")\n",
    "client.raw.tables.create(DATABASE_NAME, \"elements\")\n",
    "client.raw.tables.create(DATABASE_NAME, \"observations\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vGd1Kmg-1WfQ"
   },
   "source": [
    "List tables, we should see 3 our tables in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "s2wIBpHv1VjF",
    "outputId": "d431122e-6bdb-4381-b25e-4e9c4220fdc2"
   },
   "outputs": [],
   "source": [
    "client.raw.tables.list(db_name=DATABASE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ywhaNiMa11bb"
   },
   "source": [
    "### Import rows\n",
    "\n",
    "Upload CSV files to pandas DataFrames. Before running the cell upload files to the Colab environment or access the files from data folder in the repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TPjuYkW9nzZe"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sources_df = pd.read_csv('data/sources.csv', index_col=0).fillna('')\n",
    "elements_df = pd.read_csv('data/elements.csv', index_col=0).fillna('')\n",
    "observations_df = pd.read_csv('data/observations.csv', index_col=0).fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FFTJD6-G2OQi"
   },
   "source": [
    "Check out DataFrames. Run the cells below to display the first five rows in each data frame and check which data you have in each table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 583
    },
    "id": "iW6LO3Z02iLV",
    "outputId": "9915d83b-c0c7-4a71-dc2d-ab78aaf0f05e"
   },
   "outputs": [],
   "source": [
    "elements_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "YZXoTzxR2oGO",
    "outputId": "6ac1fa44-c03b-40ff-c95a-80ceb94e19c0"
   },
   "outputs": [],
   "source": [
    "observations_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJmr-wy82y24"
   },
   "source": [
    "Insert dataframes into RAW tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MuJ7PzrW2yDR"
   },
   "outputs": [],
   "source": [
    "client.raw.rows.insert_dataframe(DATABASE_NAME, \"sources\", sources_df)\n",
    "client.raw.rows.insert_dataframe(DATABASE_NAME, \"elements\", elements_df)\n",
    "client.raw.rows.insert_dataframe(DATABASE_NAME, \"observations\", observations_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ksFoq5IiqxbE"
   },
   "source": [
    "### Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y2Io5oWSqwi1"
   },
   "outputs": [],
   "source": [
    "from cognite.client.data_classes import DataSet\n",
    "client.data_sets.create(DataSet(external_id=DATASET_NAME, name=DATASET_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ONO9sGoAtqDP"
   },
   "outputs": [],
   "source": [
    "DATASET_ID = client.data_sets.retrieve_multiple(external_ids=[DATASET_NAME])[0].id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TGbMOpvUnA6B"
   },
   "source": [
    "### Make a root asset\n",
    "\n",
    "Organising our assets makes a root asset, which will be a parent for other created assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "It7M-EW7nD7_",
    "outputId": "4cc1192b-f900-4fde-a108-16676aeb8711"
   },
   "outputs": [],
   "source": [
    "from cognite.client.data_classes import Asset\n",
    "client.assets.create(Asset(external_id=ASSET_NAME, name=ASSET_NAME, data_set_id=DATASET_ID))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WBfNr0MX6X-m"
   },
   "source": [
    "## 3. Transformations\n",
    "\n",
    "### Create and debug queries\n",
    "\n",
    "#### Create an asset query\n",
    "\n",
    "\n",
    "Let's take a look at the sources table and make a query to create assets. To create a transformation, you should set the destination type. Each destination type has requested and optional columns. You can check the schema for a particular destination type by running the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "k-JBFa9Hl3wP",
    "outputId": "ae58ce1f-5d73-4a0d-fd85-b2cb498ebfe6"
   },
   "outputs": [],
   "source": [
    "from cognite.client.data_classes import TransformationDestination\n",
    "client.transformations.schema.retrieve(destination=TransformationDestination.asset_hierarchy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "slmAjIramjWK"
   },
   "source": [
    "Considering the required and optional columns, we compose our query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jYCAKBKS7Btx"
   },
   "outputs": [],
   "source": [
    "asset_query = f'''with \n",
    "countries as\n",
    "(select \n",
    "  distinct country as name,\n",
    "  concat('{PREFIX}-', country) as externalId,\n",
    "  '{ASSET_NAME}' as parentExternalId,\n",
    "  {DATASET_ID} as dataSetId\n",
    "from `{DATABASE_NAME}`.sources\n",
    "where country <> ''),\n",
    "  \n",
    "counties as\n",
    "(select\n",
    "  county as name,\n",
    "  concat('{PREFIX}-', 'county-', county) as externalId,\n",
    "  concat('{PREFIX}-', first(country)) as parentExternalId,\n",
    "  {DATASET_ID} as dataSetId\n",
    "from `{DATABASE_NAME}`.sources\n",
    "where county <> ''\n",
    "group by county),\n",
    "\n",
    "municipalities as\n",
    "(select\n",
    "  municipality as name,\n",
    "  concat('{PREFIX}-', 'municipality-', municipality) as externalId,\n",
    "  (\n",
    "    case\n",
    "    \twhen first(county) = '' then concat('{PREFIX}-', first(country))\n",
    "    \telse concat('{PREFIX}-', 'county-', first(county))\n",
    "\tend\n",
    "  ) as parentExternalId,\n",
    "  {DATASET_ID} as dataSetId\n",
    "from `{DATABASE_NAME}`.sources\n",
    "where municipality <> ''\n",
    "group by municipality),\n",
    "\n",
    "sensors as\n",
    "(select\n",
    "  name as name,\n",
    "  concat('{PREFIX}-', id) as externalId,\n",
    "  (\n",
    "    case\n",
    "    \twhen municipality <> '' then concat('{PREFIX}-', 'municipality-', municipality)\n",
    "  \t\twhen county <> '' then concat('{PREFIX}-', 'county-', county)\n",
    "    \telse concat('{PREFIX}-', country)\n",
    "\tend\n",
    "  ) as parentExternalId,\n",
    "  {DATASET_ID} as dataSetId,\n",
    "  to_metadata(*) as metadata\n",
    "from `{DATABASE_NAME}`.sources\n",
    ")\n",
    "  \n",
    "select * from sensors\n",
    "union all select *, null as metadata from countries\n",
    "union all select *, null as metadata from counties\n",
    "union all select *, null as metadata from municipalities'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DmuGY8mcmqSc"
   },
   "source": [
    "Query explanation: \n",
    "\n",
    "As you can see in the source table, we have different source attributes, such as country, county, and municipality. Of course, we can model this as a flat structure of Sensor Systems, but it is way more convenient to use hierarchical structures. \n",
    "\n",
    "We use the _with_ clause to define different levels of our assets. For example, we select distinct values from the _country_ column to get all the countries. Name and external id are the same in this case and we use the root asset as a parent. \n",
    "\n",
    "```\n",
    "countries as\n",
    "(select \n",
    "  distinct country as name,\n",
    "  country as externalId,\n",
    "  '{ASSET_NAME}' as parentExternalId\n",
    "from `{DATABASE_NAME}`.sources\n",
    "where country <> '')\n",
    "```\n",
    "To get the list of counties, we use the _group by_ statement. We don't use the rows with empty county fields and use the country as a parent asset.\n",
    "\n",
    "```\n",
    "counties as\n",
    "(select\n",
    "  the county as name,\n",
    "  concat('county-', county) as externalId,\n",
    "  first(country) as parentExternalId\n",
    "from `{DATABASE_NAME}`.sources\n",
    "where county <> ''\n",
    "group by county)\n",
    "```\n",
    "\n",
    "To get the municipalities we use the _group by_ statement and skip the lines without municipalities. To resolve the ParentExternalId field we use the _case_ statement. If there is a county for that municipality then we use that as a parent otherwise we use the country.\n",
    "\n",
    "```\n",
    "municipalities as\n",
    "(select\n",
    "  municipality as name,\n",
    "  concat('municipality-', municipality) as externalId,\n",
    "  (\n",
    "    case\n",
    "    \twhen first(county) = '' then first(country)\n",
    "    \telse concat('county-', first(county))\n",
    "\tend\n",
    "  ) as parentExternalId\n",
    "from `{DATABASE_NAME}`.sources\n",
    "where municipality <> ''\n",
    "group by municipality),\n",
    "```\n",
    "Each row in the table represents the sensor. So we use the _case_ statement to get the parentExternalId. If the row has a municipality, it is a parent; it could also be a county or country. Also, we use the _to\\_metadata_ function to create a column with mappings from all the original columns.\n",
    "```\n",
    "sensors as\n",
    "(select\n",
    "  name as name,\n",
    "  id as externalId,\n",
    "  (\n",
    "    case\n",
    "    \twhen municipality <> '' then concat('municipality-', municipality)\n",
    "  \t\twhen county <> '' then concat('county-', county)\n",
    "    \telse country\n",
    "\tend\n",
    "  ) as parentExternalId,\n",
    "  to_metadata(*) as metadata\n",
    "from `{DATABASE_NAME}`.sources\n",
    ")\n",
    "```\n",
    "In the end, we combine all the assets using the _union all_ statement. And since we only have metadata for sensors, we add the null columns for other levels. \n",
    "\n",
    "```\n",
    "select * from sensors\n",
    "union all select *, null as metadata from countries\n",
    "union all select *, null as metadata from counties\n",
    "union all select *, null as metadata from municipalities\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDRaJm13w-Hz"
   },
   "source": [
    "To debug the transformation via SDK, you can use the _preview_ method as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "qCDylvSmekL9",
    "outputId": "275620f7-f935-49dd-e5b3-0814428a3044"
   },
   "outputs": [],
   "source": [
    "transformation_preview = client.transformations.preview(asset_query)\n",
    "preview_df = pd.DataFrame(transformation_preview.results)\n",
    "preview_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Csile0oyRngb"
   },
   "source": [
    "### Create and run asset transformation job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IHSV6unZxUIK"
   },
   "source": [
    "Create the transformation using OIDC credentials defined above and _asset\\_query_. The fields _name_ and _external\\_id_ are mandatory when you create a transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "id": "XmvxK6xpoziS",
    "outputId": "649bcb5e-8923-434f-d623-8ec680ba028a"
   },
   "outputs": [],
   "source": [
    "from cognite.client.data_classes import Transformation, TransformationDestination, OidcCredentials\n",
    "\n",
    "transformation = Transformation(\n",
    "    name=f\"{PREFIX}-assets\",\n",
    "    external_id=f\"{PREFIX}-assets\",\n",
    "    source_oidc_credentials=creds,\n",
    "    destination_oidc_credentials=creds, \n",
    "    destination=TransformationDestination.asset_hierarchy(), \n",
    "    conflict_mode=\"upsert\", \n",
    "    query=asset_query,\n",
    ")\n",
    "client.transformations.create(transformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V24TzNjuR-c7"
   },
   "source": [
    "### Retrieve the asset transformation\n",
    "\n",
    "To retrieve the transformation you can use a several methods, the easiest one, knowing id or external_id is the retrieve method.\n",
    "\n",
    "It has the following signature:\n",
    "```\n",
    "TransformationsAPI.retrieve(id: Optional[int] = None, external_id: Optional[str] = None) → Optional[cognite.client.data_classes.transformations.Transformation]\n",
    "Retrieve a single transformation by id.\n",
    "\n",
    "Parameters:\tid (int, optional) – ID\n",
    "Returns:\tRequested transformation or None if it does not exist.\n",
    "Return type:\tOptional[Transformation]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "id": "ksT-q9MLtiVh",
    "outputId": "c7f56187-7c13-43c2-f263-07810b24f589"
   },
   "outputs": [],
   "source": [
    "asset_transformation = client.transformations.retrieve(external_id=f'{PREFIX}-assets')\n",
    "asset_transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Sub2l41uPGh"
   },
   "source": [
    "If we need to get several transformations then it's better to use retrieve_multiple. \n",
    "\n",
    "```\n",
    "TransformationsAPI.retrieve_multiple(ids: Sequence[int] = None, external_ids: Sequence[str] = None, ignore_unknown_ids: bool = False) → cognite.client.data_classes.transformations.TransformationList\n",
    "Retrieve multiple transformations.\n",
    "\n",
    "Parameters:\t\n",
    "ids (List[int]) – List of ids to retrieve.\n",
    "external_ids (List[str]) – List of external ids to retrieve.\n",
    "ignore_unknown_ids (bool) – Ignore IDs and external IDs that are not found rather than throw an exception.\n",
    "Returns:\t\n",
    "Requested transformation or None if it does not exist.\n",
    "\n",
    "Return type:\t\n",
    "TransformationList\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "id": "X8yksGlmozbB",
    "outputId": "246731ed-8a67-41f2-874a-86d1e98ecdc2"
   },
   "outputs": [],
   "source": [
    "asset_transformation = client.transformations.retrieve_multiple(external_ids=[f'{PREFIX}-assets'])[0]\n",
    "asset_transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ggBnuD5vMpr"
   },
   "source": [
    "Before the creation of the timeseries and datapoints transformations we should run the asset transformation. You can do it by id or external_id. Also, it's possible to set timeout and the flag if should wait until the transformation ends. The run method signature:\n",
    "```\n",
    "TransformationsAPI.run(transformation_id: int = None, transformation_external_id: str = None, wait: bool = True, timeout: Optional[float] = None) → cognite.client.data_classes.transformations.jobs.TransformationJob\n",
    "Run a transformation.\n",
    "\n",
    "Parameters:\t\n",
    "transformation_id (int) – Transformation internal id\n",
    "transformation_external_id (str) – Transformation external id\n",
    "wait (bool) – Wait until the transformation run is finished. Defaults to True.\n",
    "timeout (Optional[float]) – maximum time (s) to wait, default is None (infinite time). Once the timeout is reached, it returns with the current status. Won’t have any effect if wait is False.\n",
    "Returns:\t\n",
    "Created transformation job\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "usQoIuuBo-z6",
    "outputId": "f8703df0-2a82-49cf-941a-f57ad565f641"
   },
   "outputs": [],
   "source": [
    "client.transformations.run(asset_transformation.id, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "otRQcR8lv-w1"
   },
   "source": [
    "After the running we can list the jobs to check the status, or use the object returning from the run method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 271
    },
    "id": "4BGcNdroSigE",
    "outputId": "7d6dc330-4d92-4867-a214-e96eb0fc12ed"
   },
   "outputs": [],
   "source": [
    "client.transformations.jobs.list(transformation_id=asset_transformation.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upq-v24Iwj4t"
   },
   "source": [
    "A transformation object has a last_finished_job attribute which is convenient to check from API to be sure that your transformation was run and completed on time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "Jwm35rF4NOup",
    "outputId": "7c87e856-7eac-40d1-f804-83aab5e1f964"
   },
   "outputs": [],
   "source": [
    "# To get info on the latest runs, we fetch it again:\n",
    "asset_transformation = client.transformations.retrieve(external_id=f'{PREFIX}-assets')\n",
    "asset_transformation.last_finished_job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JRCg-d2o2Hwv"
   },
   "source": [
    "### Create a time series query\n",
    "\n",
    "For the beginning, let's check which fields we need to create a time series. Retrive the schema of TransformationDestination.timeseries()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xLzUqhqIst6y"
   },
   "outputs": [],
   "source": [
    "client.transformations.schema.retrieve(destination=TransformationDestination.timeseries())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RC1g4InFvoWo"
   },
   "source": [
    "Let's create a query taking into account the table data and schema fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2deW7tJw3o3z"
   },
   "outputs": [],
   "source": [
    "ts_query = f'''with measurements as\n",
    "(select\n",
    "  split(sourceId, \":\")[0] as sensor,  \n",
    "  get_json_object(observations, \"$.value\") as temp,\n",
    "  get_json_object(observations, \"$.elementId\") as measure_type,\n",
    "  get_json_object(observations, \"$.unit\") as unit\n",
    "from `{DATABASE_NAME}`.observations),\n",
    "\n",
    "ts_data as\n",
    "(select \n",
    "  unit, \n",
    "  sensor, \n",
    "  measure_type\n",
    "from measurements\n",
    "group by sensor, measure_type, unit),\n",
    "\n",
    "assets as\n",
    "(\n",
    "select \n",
    "  * \n",
    "from \n",
    "  _cdf.assets\n",
    "where\n",
    "  dataSetId = {DATASET_ID}\n",
    ")\n",
    "\n",
    "select\n",
    "  concat(sensor, '-', measure_type, '-', unit) as name,\n",
    "  concat('{PREFIX}-', sensor, '-', measure_type, '-', unit) as externalId,\n",
    "  unit as unit,\n",
    "  assets.id as assetId,\n",
    "  {DATASET_ID} as dataSetId\n",
    "from ts_data\n",
    "join assets on concat('{PREFIX}-', ts_data.sensor) = assets.externalId'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tlcfvlk2zdWq"
   },
   "source": [
    "Query explanation:\n",
    "In the _observation_ table we only have 3 columns: sourceID, referenceTime and observations. The _observations_ column contains the JSON with data. The _sourceId_ values have such a template _\\<sensor\\_id\\>:\\<number of the sensor\\>_.\n",
    "We use the _with_ clause to create needed subqueries. \n",
    "The first one is _measurements_, we split the _sourceId_ values in two parts and only use _sensor\\_id_ because we have the same values as external ids in assets. To extract the values from the _observations_ column we use the _get\\_json\\_object_ function. \n",
    "```\n",
    "measurements as\n",
    "(select\n",
    "  split(sourceId, \":\")[0] as sensor,  \n",
    "  get_json_object(observations, \"$.value\") as temp,\n",
    "  get_json_object(observations, \"$.elementId\") as measure_type,\n",
    "  get_json_object(observations, \"$.unit\") as unit\n",
    "from `{DATABASE_NAME}`.observations)\n",
    "```\n",
    "To create time series we should aggregate measurements data, we group it by sensor, measure\\_type and unit. In our case, it's redundant since we only observe the air temperature in Celsius degrees in the subset of data from MET Norway, but it's good to have this feature for future measurements.\n",
    "```\n",
    "ts_data as\n",
    "(select \n",
    "  unit, \n",
    "  sensor, \n",
    "  measure_type\n",
    "from measurements\n",
    "group by sensor, measure_type, unit)\n",
    "```\n",
    "We need to have a subquery of assets so we don't create a time series not connected to any asset. We query only assets from our data set.\n",
    "```\n",
    "assets as\n",
    "(\n",
    "select \n",
    "  * \n",
    "from \n",
    "  _cdf.assets\n",
    "where\n",
    "  dataSetId = {DATASET_ID}\n",
    ")\n",
    "```\n",
    "Finally, we format the external id and set the name, unit, assetId and dataSetId to create a dataset.\n",
    "```\n",
    "select\n",
    "  concat(sensor, '-', measure_type, '-', unit) as name,\n",
    "  concat(sensor, '-', measure_type, '-', unit) as externalId,\n",
    "  unit as unit,\n",
    "  assets.id as assetId,\n",
    "  {DATASET_ID} as dataSetId\n",
    "from ts_data\n",
    "join assets on ts_data.sensor = assets.externalId\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "Fk0OGWht3o30",
    "outputId": "7e7f52dd-433c-4b64-99d6-fed7030b2609"
   },
   "outputs": [],
   "source": [
    "tr = client.transformations.preview(ts_query, source_limit=500)\n",
    "df = pd.DataFrame(tr.results)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UC8L7lk03ts8"
   },
   "source": [
    "### Create and run timeseries transformation job\n",
    "\n",
    "We create and run the timeseries transformation in the same way we did before with the asset transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "id": "iKi5qjsw3o31",
    "outputId": "2c1daaaf-175f-49a7-b3b5-eeb8d3f8785a"
   },
   "outputs": [],
   "source": [
    "from cognite.client.data_classes import Transformation, TransformationDestination, OidcCredentials\n",
    "\n",
    "transformation = Transformation(\n",
    "    name=f\"{PREFIX}-ts\",\n",
    "    external_id=f\"{PREFIX}-ts\",\n",
    "    source_oidc_credentials=creds,\n",
    "    destination_oidc_credentials=creds, \n",
    "    destination=TransformationDestination.timeseries(), \n",
    "    conflict_mode=\"upsert\", \n",
    "    query=ts_query,\n",
    ")\n",
    "\n",
    "client.transformations.create(transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ImBBPzWF3o31"
   },
   "outputs": [],
   "source": [
    "timeseries_transformation = client.transformations.retrieve(external_id=f'{PREFIX}-ts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "X6RJ4aOp3o31",
    "outputId": "80b56a25-e43d-418c-d01e-4163d07ae2c7"
   },
   "outputs": [],
   "source": [
    "client.transformations.run(timeseries_transformation.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJl8Tkdy5CqC"
   },
   "source": [
    "Then we can check the transformation jobs list to the status of the running the timeseries transformation job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yNbeeE5B4_G8"
   },
   "outputs": [],
   "source": [
    "client.transformations.jobs.list(transformation_id=timeseries_transformation.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MezX8XQVEVHi"
   },
   "source": [
    "### Create datapoints transformation query\n",
    "\n",
    "Let's check out the schema of the datapoints destination. In CDF, you can use numeric and string data points. In our case, we want to have a numeric temperature value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "YI-GrdS0tjSQ",
    "outputId": "b3ecf455-bf5f-493f-d97a-101a3edeb249"
   },
   "outputs": [],
   "source": [
    "client.transformations.schema.retrieve(destination=TransformationDestination.datapoints())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAJv_U0Z507G"
   },
   "source": [
    "The query will be quite basic this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R1rxjh83EVHj"
   },
   "outputs": [],
   "source": [
    "query_dp = f'''with measurements as\n",
    "(select\n",
    "  split(sourceId, \":\")[0] as sensor,  \n",
    "  cast(get_json_object(observations, \"$.value\") as double) as temperature,\n",
    "  get_json_object(observations, \"$.elementId\") as measure_type,\n",
    "  get_json_object(observations, \"$.unit\") as unit,\n",
    "  to_timestamp(referenceTime) as reference_time\n",
    "from `{DATABASE_NAME}`.observations)\n",
    "\n",
    "select\n",
    "  concat('{PREFIX}-', sensor, '-', measure_type, '-', unit) as externalId,\n",
    "  reference_time as timestamp,\n",
    "  temperature as value\n",
    "from measurements'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E13nlnNA5-sX"
   },
   "source": [
    "Query explanation: as we already have a measurement table we can use it directly to get the datapoints. But let's use the temporary table for clarity. We extract all the needed data from the JSON column 'observations'.\n",
    "\n",
    "```\n",
    "with measurements as\n",
    "(select\n",
    "  split(sourceId, \":\")[0] as sensor,  \n",
    "  cast(get_json_object(observations, \"$.value\") as double) as temperature,\n",
    "  get_json_object(observations, \"$.elementId\") as measure_type,\n",
    "  get_json_object(observations, \"$.unit\") as unit,\n",
    "  to_timestamp(referenceTime) as reference_time\n",
    "from `{DATABASE_NAME}`.observations)\n",
    "```\n",
    "And then we format our data to fit the schema requirements.\n",
    "```\n",
    "select\n",
    "  concat('{PREFIX}-', sensor, '-', measure_type, '-', unit) as externalId,\n",
    "  reference_time as timestamp,\n",
    "  temperature as value\n",
    "from measurements\n",
    "```\n",
    "\n",
    "You can run the query before the creation of the transformation in the same way we did for assets and time series to check if the result looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VIpGM-45EVHk"
   },
   "outputs": [],
   "source": [
    "tr = client.transformations.preview(query_dp)\n",
    "df = pd.DataFrame(tr.results)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6h8m0QYd7uVj"
   },
   "source": [
    "### Create and run datapoints transformation\n",
    "\n",
    "To create and run the datapoints transformation we use all the same methods as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "id": "lOvfj6k-EVHk",
    "outputId": "24bd4660-a6e5-4846-a0bc-4d1e5c696714"
   },
   "outputs": [],
   "source": [
    "from cognite.client.data_classes import Transformation, TransformationDestination, OidcCredentials\n",
    "\n",
    "transformation = Transformation(\n",
    "    name=f\"{PREFIX}-dp\",\n",
    "    external_id=f\"{PREFIX}-dp\",\n",
    "    source_oidc_credentials=creds,\n",
    "    destination_oidc_credentials=creds, \n",
    "    destination=TransformationDestination.datapoints(), \n",
    "    conflict_mode=\"upsert\", \n",
    "    query=query_dp,\n",
    ")\n",
    "client.transformations.create(transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "9xM_rcfQEVHl",
    "outputId": "b14694bb-50c4-47d1-9d31-5e795647f0cd"
   },
   "outputs": [],
   "source": [
    "datapoints_transformation = client.transformations.retrieve(external_id=f'{PREFIX}-dp')\n",
    "client.transformations.run(datapoints_transformation.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zW2nknnd8NsJ"
   },
   "source": [
    "Also we can use external id to get the list of the transformation jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 904
    },
    "id": "6GFeLOey9s5z",
    "outputId": "cf685cce-ad66-4975-9e55-8164d99a8e15"
   },
   "outputs": [],
   "source": [
    "client.transformations.jobs.list(transformation_external_id=f'{PREFIX}-dp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "76miPqrHAY91"
   },
   "source": [
    "### Cancel a transformation job\n",
    "\n",
    "If your job is executed for too long you could cancel it having the job id. Let's create a transformation job and cancel it, then check the jobs list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hsai8leBZxoh",
    "outputId": "87e67051-431d-4641-d987-a50b932454ad"
   },
   "outputs": [],
   "source": [
    "datapoints_job = client.transformations.run(datapoints_transformation.id, wait=False)\n",
    "datapoints_job.cancel()\n",
    "dp_jobs = client.transformations.jobs.list(transformation_external_id=f'{PREFIX}-dp')\n",
    "dp_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ks08-eIJBjYt"
   },
   "source": [
    "You can also check the error message because the canceled job has the same status as the failed one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Ew-RatUVBXLL",
    "outputId": "b90c3f50-e210-4594-ba5f-a989de13f683"
   },
   "outputs": [],
   "source": [
    "dp_jobs[0].error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4apYhZBRCY5q"
   },
   "source": [
    "There is also a possibility to cancel job by transformation id or external id because only one job could be running in a moment for every transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "D5o7_oPcB9aL",
    "outputId": "8bf85341-bec8-42ba-9282-2f1144c97f08"
   },
   "outputs": [],
   "source": [
    "datapoints_job = client.transformations.run(datapoints_transformation.id, wait=False)\n",
    "client.transformations.cancel(transformation_external_id=f'{PREFIX}-dp')\n",
    "dp_jobs = client.transformations.jobs.list(transformation_external_id=f'{PREFIX}-dp')\n",
    "dp_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_oq1_07hvYHn"
   },
   "source": [
    "## 4. Clean up resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mL-YH6KNozKW"
   },
   "outputs": [],
   "source": [
    "# Delete RAW tables\n",
    "client.raw.tables.delete(db_name=DATABASE_NAME, name=['sources', 'elements', 'observations'])\n",
    "# Delete RAW database\n",
    "client.raw.databases.delete(name=DATABASE_NAME)\n",
    "# Delete time series\n",
    "tss = client.time_series.list(data_set_ids=[DATASET_ID], limit=-1)\n",
    "client.time_series.delete([ts.id for ts in tss])\n",
    "# Delete assets recursively\n",
    "client.assets.delete(external_id=f\"{PREFIX}-root\", recursive=True)\n",
    "# Delete transformations\n",
    "client.transformations.delete(external_id=[f\"{PREFIX}-assets\", f\"{PREFIX}-ts\", f\"{PREFIX}-dp\"])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
